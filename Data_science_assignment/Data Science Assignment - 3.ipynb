{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2529e0b",
   "metadata": {},
   "source": [
    "1. Scenario: A company wants to analyze the sales performance of its products in different regions. They have collected the following data:\n",
    "\n",
    "   Region A: [10, 15, 12, 8, 14]\n",
    "   \n",
    "   Region B: [18, 20, 16, 22, 25]\n",
    "   \n",
    "   Calculate the mean sales for each region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ed66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sales for Region A: 11.8\n",
      "Mean sales for Region B: 20.2\n"
     ]
    }
   ],
   "source": [
    "region_a_sales = [10, 15, 12, 8, 14]\n",
    "region_b_sales = [18, 20, 16, 22, 25]\n",
    "\n",
    "mean_a = sum(region_a_sales) / len(region_a_sales)\n",
    "mean_b = sum(region_b_sales) / len(region_b_sales)\n",
    "\n",
    "print(\"Mean sales for Region A:\", mean_a)\n",
    "print(\"Mean sales for Region B:\", mean_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42437e75",
   "metadata": {},
   "source": [
    "2. Scenario: A survey is conducted to measure customer satisfaction on a scale of 1 to 5. The data collected is as follows:\n",
    "\n",
    "   [4, 5, 2, 3, 5, 4, 3, 2, 4, 5]\n",
    "   \n",
    "   Calculate the mode of the survey responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9457a960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode(s) of the survey responses: [4, 5]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Survey responses\n",
    "responses = [4, 5, 2, 3, 5, 4, 3, 2, 4, 5]\n",
    "\n",
    "# Count the frequency of each value\n",
    "frequency = Counter(responses)\n",
    "\n",
    "# Find the maximum frequency\n",
    "max_frequency = max(frequency.values())\n",
    "\n",
    "# Find the mode(s) with the maximum frequency\n",
    "mode = [value for value, freq in frequency.items() if freq == max_frequency]\n",
    "\n",
    "print(\"Mode(s) of the survey responses:\", mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac572f",
   "metadata": {},
   "source": [
    "3. Scenario: A company wants to compare the salaries of two departments. The salary data for Department A and Department B are as follows:\n",
    "   Department A: [5000, 6000, 5500, 7000]\n",
    "   \n",
    "   Department B: [4500, 5500, 5800, 6000, 5200]\n",
    "   \n",
    "   Calculate the median salary for each department.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a67b5",
   "metadata": {},
   "source": [
    "To calculate the median salary for each department, we need to find the middle value(s) of the sorted salary data. If the number of values is odd, the median is the middle value. If the number of values is even, the median is the average of the two middle values. Let's calculate it step by step for each department:\n",
    "\n",
    "For Department A: [5000, 6000, 5500, 7000]\n",
    "1. Sort the salaries in ascending order: [5000, 5500, 6000, 7000]\n",
    "2. The number of values is odd (4), so the median is the middle value.\n",
    "   Median of Department A: 5500\n",
    "\n",
    "For Department B: [4500, 5500, 5800, 6000, 5200]\n",
    "1. Sort the salaries in ascending order: [4500, 5200, 5500, 5800, 6000]\n",
    "2. The number of values is odd (5), so the median is the middle value.\n",
    "   Median of Department B: 5500\n",
    "\n",
    "Therefore, the median salary for Department A is 5500, and the median salary for Department B is also 5500."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4af1e",
   "metadata": {},
   "source": [
    "4. Scenario: A data analyst wants to determine the variability in the daily stock prices of a company. The data collected is as follows:\n",
    "\n",
    "   [25.5, 24.8, 26.1, 25.3, 24.9]\n",
    "   \n",
    "   Calculate the range of the stock prices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810edcc",
   "metadata": {},
   "source": [
    "To calculate the range of the stock prices, we need to find the difference between the maximum and minimum values in the dataset. In this case, the dataset is:\n",
    "\n",
    "[25.5, 24.8, 26.1, 25.3, 24.9]\n",
    "\n",
    "Let's calculate it step by step:\n",
    "\n",
    "1. Sort the stock prices in ascending order: [24.8, 24.9, 25.3, 25.5, 26.1]\n",
    "2. The minimum value is the first value in the sorted list: 24.8\n",
    "3. The maximum value is the last value in the sorted list: 26.1\n",
    "4. Calculate the range by subtracting the minimum value from the maximum value: 26.1 - 24.8 = 1.3\n",
    "\n",
    "Therefore, the range of the stock prices is 1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e25d11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1ee749",
   "metadata": {},
   "source": [
    "5. Scenario: A study is conducted to compare the performance of two different teaching methods. The test scores of the students in each group are as follows:\n",
    "   Group A: [85, 90, 92, 88, 91]\n",
    "   \n",
    "   Group B: [82, 88, 90, 86, 87]\n",
    "   Perform a t-test to determine if there is a significant difference in the mean scores between the two groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b854ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 1.4312528946642733\n",
      "P-value: 0.19023970239078333\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Test scores for Group A and Group B\n",
    "group_a_scores = [85, 90, 92, 88, 91]\n",
    "group_b_scores = [82, 88, 90, 86, 87]\n",
    "\n",
    "# Perform independent t-test\n",
    "t_statistic, p_value = stats.ttest_ind(group_a_scores, group_b_scores)\n",
    "\n",
    "# Print the t-statistic and p-value\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29918fef",
   "metadata": {},
   "source": [
    "The t-statistic represents the magnitude of the difference between the means of the two groups, while the p-value indicates the probability of observing such a difference by chance. In this case, with a p-value of 0.190, if we consider a significance level of 0.05 (commonly used), the p-value is greater than the significance level. Therefore, we do not have sufficient evidence to reject the null hypothesis and can conclude that there is no significant difference in the mean scores between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedcf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b0b41e0",
   "metadata": {},
   "source": [
    "6. Scenario: A company wants to analyze the relationship between advertising expenditure and sales. The data collected is as follows:\n",
    "   Advertising Expenditure (in thousands): [10, 15, 12, 8, 14]\n",
    "   \n",
    "   Sales (in thousands): [25, 30, 28, 20, 26]\n",
    "   \n",
    "   Calculate the correlation coefficient between advertising expenditure and sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a793b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: 0.8757511375750132\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Advertising expenditure (in thousands) and sales (in thousands)\n",
    "advertising_expenditure = [10, 15, 12, 8, 14]\n",
    "sales = [25, 30, 28, 20, 26]\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation_coefficient = np.corrcoef(advertising_expenditure, sales)[0, 1]\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Correlation coefficient:\", correlation_coefficient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ccc98c",
   "metadata": {},
   "source": [
    "The correlation coefficient ranges from -1 to 1. A positive value indicates a positive correlation, meaning that as advertising expenditure increases, sales tend to increase as well. In this case, the correlation coefficient of  0.8757 suggests a strong positive correlation between advertising expenditure and sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d0c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd3d732f",
   "metadata": {},
   "source": [
    "7. Scenario: A survey is conducted to measure the heights of a group of people. The data collected is as follows:\n",
    "\n",
    "   [160, 170, 165, 155, 175, 180, 170]\n",
    "   \n",
    "   Calculate the standard deviation of the heights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9889c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of heights: 7.953949089757174\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Heights data\n",
    "heights = [160, 170, 165, 155, 175, 180, 170]\n",
    "\n",
    "# Calculate the standard deviation\n",
    "standard_deviation = np.std(heights)\n",
    "\n",
    "# Print the standard deviation\n",
    "print(\"Standard deviation of heights:\", standard_deviation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedfbf4a",
   "metadata": {},
   "source": [
    "8. Scenario: A company wants to analyze the relationship between employee tenure and job satisfaction. The data collected is as follows:\n",
    "   Employee Tenure (in years): [2, 3, 5, 4, 6, 2, 4]\n",
    "   \n",
    "   Job Satisfaction (on a scale of 1 to 10): [7, 8, 6, 9, 5, 7, 6]\n",
    "   \n",
    "   Perform a linear regression analysis to predict job satisfaction based on employee tenure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ac10ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression equation: job_satisfaction = -0.4680851063829787 * employee_tenure + 8.595744680851062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Employee tenure (in years) and job satisfaction\n",
    "employee_tenure = np.array([2, 3, 5, 4, 6, 2, 4]).reshape(-1, 1)\n",
    "job_satisfaction = np.array([7, 8, 6, 9, 5, 7, 6])\n",
    "\n",
    "# Create a linear regression model\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "regression_model.fit(employee_tenure, job_satisfaction)\n",
    "\n",
    "# Get the coefficients of the linear regression equation\n",
    "slope = regression_model.coef_[0]\n",
    "intercept = regression_model.intercept_\n",
    "\n",
    "# Print the linear regression equation\n",
    "print(\"Linear regression equation: job_satisfaction = {} * employee_tenure + {}\".format(slope, intercept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fc1bf",
   "metadata": {},
   "source": [
    "The linear regression equation represents the relationship between employee tenure and job satisfaction. In this case, the negative coefficient (-0.468) indicates that as employee tenure increases, job satisfaction tends to decrease slightly. The intercept term (8.5957) represents the estimated job satisfaction when the employee tenure is zero.\n",
    "\n",
    "You can use this equation to predict job satisfaction for new values of employee tenure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097de903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e540ec8f",
   "metadata": {},
   "source": [
    "9. Scenario: A study is conducted to compare the effectiveness of two different medications. The recovery times of the patients in each group are as follows:\n",
    "   Medication A: [10, 12, 14, 11, 13]\n",
    "   \n",
    "   Medication B: [15, 17, 16, 14, 18]\n",
    "   \n",
    "   Perform an analysis of variance (ANOVA) to determine if there is a significant difference in the mean recovery times between the two medications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d8c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 16.0\n",
      "P-value: 0.003949772803445326\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Recovery times for Medication A and Medication B\n",
    "medication_a_times = [10, 12, 14, 11, 13]\n",
    "medication_b_times = [15, 17, 16, 14, 18]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(medication_a_times, medication_b_times)\n",
    "\n",
    "# Print the F-statistic and p-value\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982be230",
   "metadata": {},
   "source": [
    "The F-statistic tests the null hypothesis that the means of the two groups are equal. The p-value indicates the probability of observing such a difference in means by chance. In this case, with a p-value of 0.003, if we consider a significance level of 0.05 (commonly used), the p-value is less than the significance level. Therefore, we have marginal evidence to reject the null hypothesis and conclude that there may be a significant difference in the mean recovery times between the two medications. However, the decision ultimately depends on the predetermined significance level and other factors such as sample size and study design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e2d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ddf289b",
   "metadata": {},
   "source": [
    "10. Scenario: A company wants to analyze customer feedback ratings on a scale of 1 to 10. The data collected is\n",
    "\n",
    " as follows:\n",
    "    [8, 9, 7, 6, 8, 10, 9, 8, 7, 8]\n",
    "    \n",
    "    Calculate the 75th percentile of the feedback ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3a9c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th percentile:  8.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ratings = [8, 9, 7, 6, 8, 10, 9, 8, 7, 8]\n",
    "\n",
    "percentile_75 = np.percentile(ratings, 75)\n",
    "print(\"75th percentile: \", percentile_75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae8f15",
   "metadata": {},
   "source": [
    "11. Scenario: A quality control department wants to test the weight consistency of a product. The weights of a sample of products are as follows:\n",
    "\n",
    "    [10.2, 9.8, 10.0, 10.5, 10.3, 10.1]\n",
    "    \n",
    "    Perform a hypothesis test to determine if the mean weight differs significantly from 10 grams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0cf22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 1.5126584522688367\n",
      "p-value: 0.19077595151110102\n",
      "Fail to reject null hypothesis. The mean weight does not differ significantly from 10 grams.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "weights = [10.2, 9.8, 10.0, 10.5, 10.3, 10.1]\n",
    "population_mean = 10\n",
    "\n",
    "t_statistic, p_value = ttest_1samp(weights, population_mean)\n",
    "\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis. The mean weight differs significantly from 10 grams.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis. The mean weight does not differ significantly from 10 grams.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe59f80",
   "metadata": {},
   "source": [
    "12. Scenario: A company wants to analyze the click-through rates of two different website designs. The number of clicks for each design is as follows:\n",
    "    Design A: [100, 120, 110, 90, 95]\n",
    "    \n",
    "    Design B: [80, 85, 90, 95, 100]\n",
    "    \n",
    "    Perform a chi-square test to determine if there is a significant difference in the click-through rates between the two designs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53ccfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 6.110658166925435\n",
      "p-value: 0.19103526314060296\n",
      "Fail to reject null hypothesis. There is no significant difference in click-through rates between the two designs.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "design_a = [100, 120, 110, 90, 95]\n",
    "design_b = [80, 85, 90, 95, 100]\n",
    "\n",
    "observed = [design_a, design_b]\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(observed)\n",
    "\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis. There is a significant difference in click-through rates between the two designs.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis. There is no significant difference in click-through rates between the two designs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee6a33",
   "metadata": {},
   "source": [
    "13. Scenario: A survey is conducted to measure customer satisfaction with a product on a scale of 1 to 10. The data collected is as follows:\n",
    "\n",
    "    [7, 9, 6, 8, 10, 7, 8, 9, 7, 8]\n",
    "    \n",
    "    Calculate the 95% confidence interval for the population mean satisfaction score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c4c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [7.04, 8.76]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "data = [7, 9, 6, 8, 10, 7, 8, 9, 7, 8]\n",
    "confidence_level = 0.95\n",
    "\n",
    "sample_mean = np.mean(data)\n",
    "sample_std = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "sample_size = len(data)\n",
    "\n",
    "critical_value = t.ppf((1 + confidence_level) / 2, df=sample_size - 1)\n",
    "standard_error = sample_std / np.sqrt(sample_size)\n",
    "\n",
    "confidence_interval = sample_mean + critical_value * standard_error\n",
    "\n",
    "lower_bound = sample_mean - critical_value * standard_error\n",
    "upper_bound = sample_mean + critical_value * standard_error\n",
    "\n",
    "print(\"95% Confidence Interval: [{:.2f}, {:.2f}]\".format(lower_bound, upper_bound))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc325a",
   "metadata": {},
   "source": [
    "14. Scenario: A company wants to analyze the effect of temperature on product performance. The data collected is as follows:\n",
    "    Temperature (in degrees Celsius): [20, 22, 23, 19, 21]\n",
    "    \n",
    "    Performance (on a scale of 1 to 10): [8, 7, 9, 6, 8]\n",
    "    \n",
    "    Perform a simple linear regression to predict performance based on temperature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cda4082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 0.5\n",
      "Intercept: -2.9000000000000004\n",
      "R-squared: 0.4807692307692307\n",
      "p-value: 0.19417134561205843\n",
      "Standard error: 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "temperature = np.array([20, 22, 23, 19, 21])\n",
    "performance = np.array([8, 7, 9, 6, 8])\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(temperature, performance)\n",
    "\n",
    "print(\"Slope:\", slope)\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"R-squared:\", r_value**2)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Standard error:\", std_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54504ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce52ab67",
   "metadata": {},
   "source": [
    "15. Scenario: A study is conducted to compare the preferences of two groups of participants. The preferences are measured on a Likert scale from 1 to 5. The data collected is as follows:\n",
    "    Group A: [4, 3, 5, 2, 4]\n",
    "    \n",
    "    Group B: [3, 2, 4, 3, 3]\n",
    "    \n",
    "    Perform a Mann-Whitney U test to determine if there is a significant difference in the median preferences between the two groups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78899f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U statistic: 17.0\n",
      "p-value: 0.380836480306712\n",
      "Fail to reject null hypothesis. There is no significant difference in median preferences between the two groups.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "group_a = [4, 3, 5, 2, 4]\n",
    "group_b = [3, 2, 4, 3, 3]\n",
    "\n",
    "statistic, p_value = mannwhitneyu(group_a, group_b, alternative='two-sided')\n",
    "\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "print(\"Mann-Whitney U statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis. There is a significant difference in median preferences between the two groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis. There is no significant difference in median preferences between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08d504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a14d8b3",
   "metadata": {},
   "source": [
    "16. Scenario: A company wants to analyze the distribution of customer ages. The data collected is as follows:\n",
    "    [25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "    \n",
    "    Calculate the interquartile range (IQR) of the ages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146246d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interquartile Range (IQR): 22.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ages = [25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "\n",
    "Q1 = np.percentile(ages, 25)\n",
    "Q3 = np.percentile(ages, 75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(\"Interquartile Range (IQR):\", IQR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7809fd0",
   "metadata": {},
   "source": [
    "17. Scenario: A study is conducted to compare the performance of three different machine learning algorithms. The accuracy scores for each algorithm are as follows:\n",
    "\n",
    "    Algorithm A: [0.85, 0.80, 0.82, 0.87, 0.83]\n",
    "    \n",
    "    Algorithm B: [0.78, 0.82, 0.84, 0.80, 0.79]\n",
    "    \n",
    "    Algorithm C: [0.90, 0.88, 0.89, 0.86, 0.87]\n",
    "    Perform a Kruskal-Wallis test to determine if there is a significant difference in the median accuracy scores between the algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f54780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis statistic: 9.696947935368053\n",
      "p-value: 0.007840333026249539\n",
      "Reject null hypothesis. There is a significant difference in median accuracy scores between the algorithms.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "algorithm_a = [0.85, 0.80, 0.82, 0.87, 0.83]\n",
    "algorithm_b = [0.78, 0.82, 0.84, 0.80, 0.79]\n",
    "algorithm_c = [0.90, 0.88, 0.89, 0.86, 0.87]\n",
    "\n",
    "statistic, p_value = kruskal(algorithm_a, algorithm_b, algorithm_c)\n",
    "\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "print(\"Kruskal-Wallis statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis. There is a significant difference in median accuracy scores between the algorithms.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis. There is no significant difference in median accuracy scores between the algorithms.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800d103",
   "metadata": {},
   "source": [
    "18. Scenario: A company wants to analyze the effect of price on sales. The data collected is as follows:\n",
    "    Price (in dollars): [10, 15, 12, 8, 14]\n",
    "    \n",
    "    Sales: [100, 80, 90, 110, 95]\n",
    "    Perform a simple linear regression to predict\n",
    "\n",
    " sales based on price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99c7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: -3.506097560975609\n",
      "Intercept: 136.3719512195122\n",
      "R-squared: 0.8064024390243901\n",
      "p-value: 0.03850178234753776\n",
      "Standard error: 0.9918303504036147\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "price = np.array([10, 15, 12, 8, 14])\n",
    "sales = np.array([100, 80, 90, 110, 95])\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(price, sales)\n",
    "\n",
    "print(\"Slope:\", slope)\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"R-squared:\", r_value**2)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Standard error:\", std_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656d9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "721d94ac",
   "metadata": {},
   "source": [
    "\n",
    "19. Scenario: A survey is conducted to measure the satisfaction levels of customers with a new product. The data collected is as follows:\n",
    "\n",
    "    [7, 8, 9, 6, 8, 7, 9, 7, 8, 7]\n",
    "    \n",
    "    Calculate the standard error of the mean satisfaction score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967551c",
   "metadata": {},
   "source": [
    "To calculate the standard error of the mean satisfaction score, you need to divide the standard deviation of the data by the square root of the sample size. Here are the steps:\n",
    "\n",
    "1. Calculate the mean of the satisfaction scores:\n",
    "   Mean = (7 + 8 + 9 + 6 + 8 + 7 + 9 + 7 + 8 + 7) / 10 = 76 / 10 = 7.6\n",
    "\n",
    "2. Calculate the differences between each satisfaction score and the mean:\n",
    "   Differences = [7 - 7.6, 8 - 7.6, 9 - 7.6, 6 - 7.6, 8 - 7.6, 7 - 7.6, 9 - 7.6, 7 - 7.6, 8 - 7.6, 7 - 7.6]\n",
    "               = [-0.6, 0.4, 1.4, -1.6, 0.4, -0.6, 1.4, -0.6, 0.4, -0.6]\n",
    "\n",
    "3. Square each difference:\n",
    "   Squared Differences = [(-0.6)^2, 0.4^2, 1.4^2, (-1.6)^2, 0.4^2, (-0.6)^2, 1.4^2, (-0.6)^2, 0.4^2, (-0.6)^2]\n",
    "                      = [0.36, 0.16, 1.96, 2.56, 0.16, 0.36, 1.96, 0.36, 0.16, 0.36]\n",
    "\n",
    "4. Calculate the variance by taking the average of the squared differences:\n",
    "   Variance = (0.36 + 0.16 + 1.96 + 2.56 + 0.16 + 0.36 + 1.96 + 0.36 + 0.16 + 0.36) / 10\n",
    "            = 9.08 / 10\n",
    "            = 0.908\n",
    "\n",
    "5. Calculate the standard deviation by taking the square root of the variance:\n",
    "   Standard Deviation = √0.908 ≈ 0.953\n",
    "\n",
    "6. Calculate the standard error of the mean by dividing the standard deviation by the square root of the sample size:\n",
    "   Standard Error = 0.953 / √10 ≈ 0.301\n",
    "\n",
    "Therefore, the standard error of the mean satisfaction score is approximately 0.301."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1751f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e09b7a2",
   "metadata": {},
   "source": [
    "20. Scenario: A company wants to analyze the relationship between advertising expenditure and sales. The data collected is as follows:\n",
    "    Advertising Expenditure (in thousands): [10, 15, 12, 8, 14]\n",
    "    Sales (in thousands): [25, 30, 28, 20, 26]\n",
    "    Perform a multiple regression analysis to predict sales based on advertising expenditure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baaf910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/9.2 MB 6.4 MB/s eta 0:00:02\n",
      "      --------------------------------------- 0.1/9.2 MB 1.4 MB/s eta 0:00:07\n",
      "      --------------------------------------- 0.2/9.2 MB 1.3 MB/s eta 0:00:07\n",
      "      --------------------------------------- 0.2/9.2 MB 1.2 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.3/9.2 MB 1.0 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.3/9.2 MB 1.1 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.3/9.2 MB 1.0 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.4/9.2 MB 1.0 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.4/9.2 MB 981.2 kB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.5/9.2 MB 938.8 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.5/9.2 MB 932.7 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.5/9.2 MB 945.8 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.6/9.2 MB 956.9 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.6/9.2 MB 958.5 kB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.7/9.2 MB 967.4 kB/s eta 0:00:09\n",
      "     --- ------------------------------------ 0.7/9.2 MB 975.2 kB/s eta 0:00:09\n",
      "     --- ------------------------------------ 0.8/9.2 MB 976.5 kB/s eta 0:00:09\n",
      "     --- ------------------------------------ 0.8/9.2 MB 975.8 kB/s eta 0:00:09\n",
      "     --- ------------------------------------ 0.9/9.2 MB 965.4 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 0.9/9.2 MB 971.6 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 0.9/9.2 MB 961.7 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.0/9.2 MB 952.6 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.0/9.2 MB 958.5 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.1/9.2 MB 950.2 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.1/9.2 MB 943.6 kB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.1/9.2 MB 932.4 kB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.2/9.2 MB 938.3 kB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.2/9.2 MB 928.1 kB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.3/9.2 MB 944.8 kB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.3/9.2 MB 931.6 kB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.4/9.2 MB 936.7 kB/s eta 0:00:09\n",
      "     ------ --------------------------------- 1.4/9.2 MB 918.6 kB/s eta 0:00:09\n",
      "     ------ --------------------------------- 1.5/9.2 MB 933.3 kB/s eta 0:00:09\n",
      "     ------ --------------------------------- 1.5/9.2 MB 937.9 kB/s eta 0:00:09\n",
      "     ------ --------------------------------- 1.6/9.2 MB 939.3 kB/s eta 0:00:09\n",
      "     ------ --------------------------------- 1.6/9.2 MB 946.4 kB/s eta 0:00:09\n",
      "     ------- -------------------------------- 1.6/9.2 MB 938.4 kB/s eta 0:00:09\n",
      "     ------- -------------------------------- 1.7/9.2 MB 950.9 kB/s eta 0:00:08\n",
      "     ------- -------------------------------- 1.7/9.2 MB 948.9 kB/s eta 0:00:08\n",
      "     ------- -------------------------------- 1.8/9.2 MB 955.7 kB/s eta 0:00:08\n",
      "     ------- -------------------------------- 1.8/9.2 MB 940.5 kB/s eta 0:00:08\n",
      "     -------- ------------------------------- 1.9/9.2 MB 946.5 kB/s eta 0:00:08\n",
      "     -------- ------------------------------- 1.9/9.2 MB 949.8 kB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.0/9.2 MB 950.6 kB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.0/9.2 MB 956.1 kB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.1/9.2 MB 957.1 kB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.1/9.2 MB 966.4 kB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.2/9.2 MB 955.7 kB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.2/9.2 MB 946.8 kB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.3/9.2 MB 963.3 kB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 2.3/9.2 MB 967.9 kB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 2.4/9.2 MB 972.3 kB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 2.4/9.2 MB 980.7 kB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 2.5/9.2 MB 972.9 kB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 2.5/9.2 MB 980.7 kB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 2.6/9.2 MB 990.8 kB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 2.6/9.2 MB 988.7 kB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 2.7/9.2 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 2.8/9.2 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 2.9/9.2 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 2.9/9.2 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.0/9.2 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 3.1/9.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 3.1/9.2 MB 1.0 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 3.2/9.2 MB 1.0 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 3.3/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 3.3/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 3.4/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 3.5/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 3.6/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------- ------------------------ 3.7/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 3.7/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 3.7/9.2 MB 1.1 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 3.8/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 3.9/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 4.0/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 4.1/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 4.1/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 4.2/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 4.3/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 4.4/9.2 MB 1.1 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 4.5/9.2 MB 1.2 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 4.5/9.2 MB 1.2 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 4.6/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 4.7/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 4.8/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 4.8/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 4.9/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 5.0/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 5.0/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 5.1/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 5.2/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 5.3/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 5.4/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 5.4/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 5.5/9.2 MB 1.2 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 5.6/9.2 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 5.7/9.2 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 5.8/9.2 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 5.9/9.2 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 5.9/9.2 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 6.0/9.2 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 6.1/9.2 MB 1.2 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 6.2/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 6.2/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 6.3/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 6.4/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 6.5/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 6.6/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 6.7/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 6.8/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 6.9/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 7.0/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 7.1/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.2/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 7.3/9.2 MB 1.2 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 7.5/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 7.7/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 7.8/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 7.9/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 7.9/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 7.9/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 8.1/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 8.3/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 8.4/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 8.5/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 8.5/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 8.7/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 8.8/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 8.8/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 8.9/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.0/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.1/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.2/9.2 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from statsmodels) (1.11.1)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from statsmodels) (1.25.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from statsmodels) (23.0)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "     ---------------------------------------- 0.0/233.8 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 143.4/233.8 kB 8.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 225.3/233.8 kB 4.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 225.3/233.8 kB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 233.8/233.8 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\viksb\\miniconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.3 statsmodels-0.14.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.767\n",
      "Model:                            OLS   Adj. R-squared:                  0.689\n",
      "Method:                 Least Squares   F-statistic:                     9.872\n",
      "Date:                Thu, 13 Jul 2023   Prob (F-statistic):             0.0516\n",
      "Time:                        16:49:29   Log-Likelihood:                -9.5288\n",
      "No. Observations:                   5   AIC:                             23.06\n",
      "Df Residuals:                       3   BIC:                             22.28\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         12.2012      4.429      2.755      0.070      -1.893      26.296\n",
      "x1             1.1524      0.367      3.142      0.052      -0.015       2.320\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.136\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.546\n",
      "Skew:                          -0.267   Prob(JB):                        0.761\n",
      "Kurtosis:                       1.471   Cond. No.                         57.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viksb\\miniconda3\\lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "! pip install statsmodels\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "advertising_expenditure = np.array([10, 15, 12, 8, 14])\n",
    "sales = np.array([25, 30, 28, 20, 26])\n",
    "\n",
    "# Add a constant term to the predictor variable\n",
    "X = sm.add_constant(advertising_expenditure)\n",
    "\n",
    "# Create the OLS (Ordinary Least Squares) model\n",
    "model = sm.OLS(sales, X)\n",
    "\n",
    "# Fit the model to the data\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the regression analysis\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08699ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
